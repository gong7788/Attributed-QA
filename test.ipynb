{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_path = \"train1.json\"\n",
    "with open(data_path, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['topic_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': 'Summarize the whole meeting.',\n",
       "  'answer': 'This was the kick-off meeting for the project. First of all, Project Manager led each group member to know each other and introduced the project which was aiming to design remote control. Next, they discussed their favourite animal characteristics. Lastly, Project Manager mentioned how they worked on each part individually.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['general_query_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': \"Summarize the groupmates' self-introduction and the project introduction.\",\n",
       "  'answer': 'There were four people in the project team and each one introduced to each other on the team role. Project Manager introduced the project was about designing a remote control. After that, Project Manager explained the work division for each person and how they would present in the coming meetings.',\n",
       "  'relevant_text_span': [['0', '20']]},\n",
       " {'query': 'Summarize the job role for each groupmate.',\n",
       "  'answer': 'The group was greeting each other at the first meeting. Laura was the Project Manager. David was Industrial Designer and Andrew was Marketing expert. And User Interface was named Craig.',\n",
       "  'relevant_text_span': [['0', '9']]},\n",
       " {'query': 'What did the group discuss about the email they received on the project announcement?',\n",
       "  'answer': 'Group mates all should have received an email introducing what was this project about and there would be three different stages to the design. The project was about designing a new remote control, which was supposed to be original, trendy, and user friendly.',\n",
       "  'relevant_text_span': [['9', '20']]},\n",
       " {'query': 'Summarize the discussion about the favourite animal characteristics and the workflow.',\n",
       "  'answer': 'Industrial Designer drew a whale because whales came in and went to eat everything in sight, and they were harmless, interesting, and mild. Project Manager drew a dog because the dogs were friendly and cheery. Next, about the finance and the workflow. The target revenue was fifty million Euros and the target was on an international scale. The cost was 25 Euros. Group mates would receive requirement emails and work on them individually.',\n",
       "  'relevant_text_span': [['21', '286']]},\n",
       " {'query': 'What did Project Manager recommend to do when discussing competitor information?',\n",
       "  'answer': 'Project manager mentioned that they had no background information on the competitor, however, they could analyze based on the product price. And Marketing supplemented that the remote control was something that people would not consciously assess in their purchasing habits.',\n",
       "  'relevant_text_span': [['169', '179']]},\n",
       " {'query': 'What did the group think of the importance of technology reasonable on the working design?',\n",
       "  'answer': 'The group had a discussion about the first remote control with cable and huge buttons on it. So they would like to try new technology like a touch screen and nicer materials for the remote, which was important for technology improvement.',\n",
       "  'relevant_text_span': [['223', '251']]}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['specific_query_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'speaker': 'Project Manager',\n",
       "  'content': \"Okay Right {vocalsound} Um well this is the kick-off meeting for our our project . Um {vocalsound} and um this is just what we're gonna be doing over the next twenty five minutes . Um so first of all , just to kind of make sure that we all know each other ,\"},\n",
       " {'speaker': 'Marketing', 'content': 'Mm-hmm .'},\n",
       " {'speaker': 'Project Manager',\n",
       "  'content': \"I'm Laura and I'm the project manager . {vocalsound} Do you want to introduce yourself again ?\"},\n",
       " {'speaker': 'Marketing', 'content': 'Great .'},\n",
       " {'speaker': 'Industrial Designer',\n",
       "  'content': \"Hi , I'm David and I'm supposed to be an industrial designer .\"}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['meeting_transcripts'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(text):\n",
    "    text = text.replace('{vocalsound}', '')\n",
    "    text = text.replace('{disfmarker} ', '')\n",
    "    text = text.replace('a_m_i_', 'ami')\n",
    "    text = text.replace('l_c_d_', 'lcd')\n",
    "    text = text.replace('p_m_s', 'pms')\n",
    "    text = text.replace('t_v_', 'tv')\n",
    "    text = text.replace('{pause} ', '')\n",
    "    text = text.replace('{nonvocalsound} ', '')\n",
    "    text = text.replace('{gap} ', '')\n",
    "    return text\n",
    "\n",
    "def extract_text_from_json(json_data):\n",
    "    data = []\n",
    "    for turn, meeting in enumerate(json_data['meeting_transcripts']):\n",
    "        if meeting:\n",
    "            data.append({\n",
    "                'turn': turn,\n",
    "                'speaker': meeting['speaker'],\n",
    "                'content': clean_data(meeting['content']),\n",
    "            })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = extract_text_from_json(data)\n",
    "with open(\"data.jsonl\", \"w\") as f:\n",
    "    for example in temp:\n",
    "        f.write(f\"{json.dumps(example)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-39e892dff8c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msentence_transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import sentence_transformers\n",
    "\n",
    "def get_embeddings(batch, model):\n",
    "    embeddings = model.encode(batch[\"text\"])\n",
    "    return {\"embeddings\": embeddings}\n",
    "\n",
    "model = sentence_transformers.SentenceTransformer(\n",
    "    \"sentence-transformers/multi-qa-mpnet-base-dot-v1\",\n",
    ")\n",
    "\n",
    "dataset = datasets.load_dataset(\"json\", data_files=\"data.jsonl\", split=\"train\")\n",
    "dataset = dataset.map(get_embeddings, batched=True, batch_size=32, fn_kwargs={\"model\": model})\n",
    "dataset = dataset.with_format(\n",
    "    type=\"numpy\", columns=[\"embeddings\"], output_all_columns=True,\n",
    ")\n",
    "dataset.add_faiss_index(\"embeddings\")\n",
    "dataset.save_faiss_index(\"embeddings\", \"index.faiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain import OpenAI\n",
    "from langchain.document_loaders import JSONLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents:287\n"
     ]
    }
   ],
   "source": [
    "loader = JSONLoader(\n",
    "    file_path='data.json',\n",
    "    jq_schema='.[].content',\n",
    ")\n",
    "document = loader.load()\n",
    "print(f'documents:{len(document)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents:257\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 0\n",
    ")\n",
    "# remove empty documents\n",
    "split_documents = text_splitter.split_documents(document)\n",
    "print(f'documents:{len(split_documents)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/afs/inf.ed.ac.uk/user/s17/s1756255/Attributed-QA/test.ipynb 单元格 12\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/afs/inf.ed.ac.uk/user/s17/s1756255/Attributed-QA/test.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 加载 llm 模型\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/afs/inf.ed.ac.uk/user/s17/s1756255/Attributed-QA/test.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m llm \u001b[39m=\u001b[39m OpenAI(model_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-davinci-003\u001b[39;49m\u001b[39m\"\u001b[39;49m, max_tokens\u001b[39m=\u001b[39;49m\u001b[39m1500\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/afs/inf.ed.ac.uk/user/s17/s1756255/Attributed-QA/test.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# 创建总结链\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/afs/inf.ed.ac.uk/user/s17/s1756255/Attributed-QA/test.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m chain \u001b[39m=\u001b[39m load_summarize_chain(llm, chain_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrefine\u001b[39m\u001b[39m\"\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/gpt/lib/python3.8/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for OpenAI\n__root__\n  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\", max_tokens=1500)\n",
    "\n",
    "chain = load_summarize_chain(llm, chain_type=\"refine\", verbose=True)\n",
    "\n",
    "chain.run(split_documents[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "886e96e55049b9f9d1b2054fb260cebc3be0a401e683fe9bea54e3fefc93bd78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
